import cv2
from ultralytics import YOLO
import numpy
import requests
from pydantic import BaseModel

def send_line_notify(message, image_path):
    url = "https://notify-api.line.me/api/notify"
    token = "PxOmKMhv4eNST4tacpYl1yQ8GqczL1tVQTa04lWBa55"  # Replace with your Line Notify token
    headers = {"Authorization": "Bearer " + token}

    payload = {"message": message}
    r = requests.post(url, headers=headers, data=payload)

    # Send image
    files = {"imageFile": open(image_path, "rb")}
    r = requests.post(url, headers=headers, data=payload, files=files)

class GetKeypoint(BaseModel):
    NOSE:           int = 0
    LEFT_EYE:       int = 1
    RIGHT_EYE:      int = 2
    LEFT_EAR:       int = 3
    RIGHT_EAR:      int = 4
    LEFT_SHOULDER:  int = 5
    RIGHT_SHOULDER: int = 6
    LEFT_ELBOW:     int = 7
    RIGHT_ELBOW:    int = 8
    LEFT_WRIST:     int = 9
    RIGHT_WRIST:    int = 10
    LEFT_HIP:       int = 11
    RIGHT_HIP:      int = 12
    LEFT_KNEE:      int = 13
    RIGHT_KNEE:     int = 14
    LEFT_ANKLE:     int = 15
    RIGHT_ANKLE:    int = 16


model = YOLO('yolov8n-pose.pt')

video_path = 0
cap = cv2.VideoCapture(video_path)

frame_time = 0

while cap.isOpened():
    success, frame = cap.read()
    boxes=[]
    annotations_frame = frame
    if success:
        result = model(frame, save=True)
        
        annotations_frame = result[0].plot()

        for detection in result:
            boxes = detection.boxes.xywhn.cpu().numpy()
            
            person = detection.boxes.shape
            person = int(person[0])

            if boxes.all():
                for i in range(person):
                   
                    x, y, w, h = boxes[i]
                    x1, y1 = int(float(x - w / 2)*480), int(float(y - h / 2)*640)
                    x2, y2 = int(float(x + w / 2)*480), int(float(y + h / 2)*640)
                    #print("shape : ",shape)
                    #print("x1x2y1y2 : ",x1,x2,y1,y2)
                    get_keypoint = GetKeypoint()
                    result_keypoint = detection.keypoints.xyn.cpu().numpy()
                    #print(detection.boxes)
                    #print(person)
                   
                    right_hip_x, right_hip_y = result_keypoint[i][get_keypoint.RIGHT_HIP]
                    right_shd_x, right_shd_y = result_keypoint[i][get_keypoint.RIGHT_SHOULDER]
                    left_hip_x, left_hip_y = result_keypoint[i][get_keypoint.LEFT_HIP]
                    left_shd_x, left_shd_y = result_keypoint[i][get_keypoint.LEFT_SHOULDER]

        
                    if (right_hip_y or left_hip_y) != 1:

                        if abs(right_hip_x - right_shd_x) > abs(right_hip_y - right_shd_y):
                            print("falling............")
                            cv2.putText(annotations_frame, " FALLING FOUND ", (20, 450), cv2.FONT_HERSHEY_PLAIN, 2, (218, 224, 159), 2)
                           
                            frame_time = frame_time +1
                            if frame_time % 2 == 0 and frame_time != 0 :
                                print("Notificate to LINE  Successfully......")
                                image_path = "falling_person.jpg"
                                cv2.imwrite(image_path, annotations_frame)
                                
                                
                                # Send Line notification with image
                                message = "Falling person detected!"
                                send_line_notify(message, image_path)
                                frame_time = 0

                        if abs(left_hip_x - left_shd_x) > abs(left_hip_y - left_shd_y):
                            print("falling............")
                            cv2.putText(annotations_frame, " FALLING FOUND ", (20, 450), cv2.FONT_HERSHEY_PLAIN, 2, (218, 224, 159), 2)
                            
                            frame_time = frame_time+1
                            if frame_time % 2 == 0 and frame_time != 0 :
                                print("Notificate to LINE  Successfully......")
                                image_path = "falling_person.jpg"
                                cv2.imwrite(image_path, annotations_frame)
                                
                                
                                # Send Line notification with image
                                message = "Falling person detected!"
                                send_line_notify(message, image_path)
                                frame_time = 0

    cv2.imshow("pose estimated", annotations_frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break
   

cap.release()
cv2.destroyAllWindows()
